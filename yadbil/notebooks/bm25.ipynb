{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yadbil.data.processing import calculate_idf\n",
    "from yadbil.graph import GraphProcessor, find_similar_posts_pagerank, get_graph_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA = \"data/result.json\"\n",
    "\n",
    "GRAPH_FILE_PATH = \"data/filtered_graph.graphml\"\n",
    "POSTS_FILE_PATH = \"data/posts.json\"\n",
    "POSTS_VIEW_FILE_PATH = \"data/posts_view.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from yadbil.data.text.processing import TextPreprocessor\n",
    "\n",
    "\n",
    "text_processor = TextPreprocessor()\n",
    "\n",
    "\n",
    "def get_stemmed(text):\n",
    "    return list(text_processor.preprocess(text)[\"stemmed_to_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for p in Path(\"data/tg_data/clean\").glob(\"*\"):\n",
    "    with open(p) as file:\n",
    "        d = [{\"channel\": p.stem, **json.loads(x)} for x in file]\n",
    "        d = [{**x, \"stemmed_words\": get_stemmed(x[\"text_no_links\"])} for x in d]\n",
    "    data.extend(d)\n",
    "\n",
    "with open(\"data/tg_data/whole_stemmed.json\", \"w\") as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/tg_data/whole_stemmed.json\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bm25s\n",
    "\n",
    "\n",
    "# Create the BM25 model and index the corpus\n",
    "retriever = bm25s.BM25()\n",
    "retriever.index([x[\"stemmed_words\"] for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the corpus\n",
    "query = \"мерж моделей\"\n",
    "query_tokens = get_stemmed(query)\n",
    "\n",
    "# Get top-k results as a tuple of (doc ids, scores). Both are arrays of shape (n_queries, k)\n",
    "results, scores = retriever.retrieve([query_tokens], k=10)\n",
    "\n",
    "for i in range(results.shape[1]):\n",
    "    doc, score = results[0, i], scores[0, i]\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): {doc}\")\n",
    "    print(\"-\")\n",
    "    print(data[doc][\"channel\"])\n",
    "    print(\"-\")\n",
    "    print(data[doc][\"orig_text\"])\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# ...and load them when you need them\n",
    "# import bm25s\n",
    "# reloaded_retriever = bm25s.BM25.load(\"animal_index_bm25\", load_corpus=True)\n",
    "# set load_corpus=False if you don't need the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can save the arrays to a directory...\n",
    "retriever.save(\"data/bm_25_index_tg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_scores = calculate_idf(data, min_max_scale=True)\n",
    "\n",
    "graph_proc = GraphProcessor(data, idf_scores)\n",
    "\n",
    "print(f\"Number of nodes: {graph_proc.G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {graph_proc.G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Full graph:\", len(graph_proc.G.edges))\n",
    "graph_proc.scale_edge_weights()\n",
    "G_filtered = graph_proc.filter_edges_by_threshold(threshold=0.4)\n",
    "print(\"Filtered graph:\", len(G_filtered.edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_graph_plot(G_filtered, idf_scores)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "post_id = 2759  # Replace with the desired post ID\n",
    "top_n = 5  # Replace with the desired number of top similar posts\n",
    "\n",
    "similar_posts = find_similar_posts_pagerank(G_filtered, post_id, top_n)\n",
    "\n",
    "print(f\"Top {top_n} similar posts to post {post_id}:\")\n",
    "for post, score in similar_posts:\n",
    "    print(f\"Post ID: {post}, Similarity Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Accessing edge weights\n",
    "for u, v, data in G_filtered.edges(552, data=True):\n",
    "    weight = data.get(\"weight\", 0)  # Defaulting to 0 if weight not present\n",
    "    print(f\"Edge from {u} to {v} with weight: {weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: improve comparison\n",
    "\n",
    "# a = set(posts_view[\"channel1150855655\"][545]['stemmed_words'])\n",
    "# b = set(posts_view[\"channel1150855655\"][905]['stemmed_words'])\n",
    "\n",
    "# print(posts_view[\"channel1150855655\"][700]['text'])\n",
    "\n",
    "# a.intersection(b)\n",
    "# G_filtered.nodes[545]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "G_converted = G_filtered.copy()\n",
    "\n",
    "for node, attrs in G_converted.nodes(data=True):\n",
    "    for attr_key, attr_value in attrs.items():\n",
    "        attrs[attr_key] = json.dumps(attr_value)\n",
    "\n",
    "nx.write_graphml(G_converted, GRAPH_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(POSTS_FILE_PATH, \"w\") as file:\n",
    "#     json.dump(posts, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# with open(POSTS_VIEW_FILE_PATH, \"w\") as file:\n",
    "#     json.dump(posts_view, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check loading\n",
    "\n",
    "NOTE: keys from dict from int transform into str after loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yadbil.graph.io import load_resources\n",
    "\n",
    "\n",
    "GRAPH_FILE_PATH = \"data/filtered_graph.graphml\"\n",
    "POSTS_FILE_PATH = \"data/posts.json\"\n",
    "POSTS_VIEW_FILE_PATH = \"data/posts_view.json\"\n",
    "\n",
    "G_filtered_2, posts_2, posts_view_2 = load_resources(GRAPH_FILE_PATH, POSTS_FILE_PATH, POSTS_VIEW_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_filtered_2 == G_filtered\n",
    "# len(G_filtered_2), len(G_filtered)\n",
    "# len(G_filtered_2.edges), len(G_filtered.edges)\n",
    "# list(posts_view.values())[0][65]\n",
    "# list(posts_view_2.values())[0][\"65\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "post_id = 545  # Replace with the desired post ID\n",
    "top_n = 10  # Replace with the desired number of top similar posts\n",
    "\n",
    "similar_posts = find_similar_posts_pagerank(G_filtered_2, str(post_id), top_n)\n",
    "\n",
    "print(f\"Top {top_n} similar posts to post {post_id}:\")\n",
    "for post, score in similar_posts:\n",
    "    print(f\"Post ID: {post}, Similarity Score: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
